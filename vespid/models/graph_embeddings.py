import dgl
from dgl.data import DGLDataset
import dgl.nn.pytorch as dglnn
import dgl.function as fn
import dgl.nn as dglnn

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import logging
from vespid import setup_logger
from vespid.data.neo4j_tools import Neo4jConnectionHandler
import numpy as np
import pandas as pd
import time
import argparse
import tqdm
import glob
import os

from pytorch_lightning.metrics import Accuracy
from pytorch_lightning.callbacks import Callback
from pytorch_lightning import LightningDataModule, LightningModule

import sklearn.linear_model as lm
from sklearn.multioutput import MultiOutputClassifier
import sklearn.metrics as skm
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

logger = setup_logger(module_name=__name__)
os.environ['DGLBACKEND'] = 'pytorch'

DIRECTED = True # dictates if we use directed graphs or not for model training and inference

def mask_from_ids(n, ids):
    '''
    Using node or edge IDs list, creates a mask for the 
    entire node/edge set to identify the IDs of interest.
    Note that these masks are useful graph properties
    to persist for downstream analyses.
    
    
    Parameters
    ----------
    n: int. The size of the full dataset (e.g. `g.num_nodes()`).
    
    ids: numpy array of integers. Indicates the index of items
        of interest (e.g. training nodes).
        
        
    Returns
    -------
    torch.Tensor() of bool values indicating the indices of the
    IDs of interest. Will be of shape (n,).
    '''
    
    mask = torch.zeros((n,), dtype=torch.bool)
    mask[ids] = True
    
    return mask

def ids_from_masks(g, mask, data_type='nodes'):
    '''
    Given a graph and a boolean mask, find the IDs of
    the relevant data entities that are True in the mask.


    Parameters
    ----------
    g: DGL graph.

    mask: str. Name of the property in ``g`` that contains the mask.

    data_type: str. Must be one of ['nodes', 'edges']. Indicates
        which property type to access from the graph for the mask.


    Returns
    -------
    PyTorch Tensor containing the IDs generated by the mask.
    '''
    if data_type == 'nodes':
        ids = torch.nonzero(g.ndata[mask], as_tuple=True)[0]

    elif data_type == 'edges':
        ids = torch.nonzero(g.edata[mask], as_tuple=True)[0]

    else:
        raise ValueError(f"data_type value of '{data_type}' not valid")

    return ids

class CitationDataset(DGLDataset):
    def __init__(
        self, 
        connection_handler, 
        node_query, 
        edge_query, 
        directed=DIRECTED, 
        train_fraction=0.6, 
        val_fraction=0.2,
        random_masks=False
    ):
        '''
        Creates a DGLDataset using Neo4j queries to pull from an active database. As the intent
        is that this will be a single graph in the end, recommended usage is:

            dataset = CitationDatset(connection_handler=graph, node_query=node_query, edge_query=edge_query)
            g = dataset[0]
        
        
        Parameters
        ----------
        connection_handler: vespid.data.Neo4jConnectionHandler object. 
            Provides the connection to the active Neo4j graph DB.
            
        node_query: str. Cypher query to use for pulling down node information for modeling.
            Should return columns ['nodeId', 'features', 'labels']. nodeId column  should 
            be queried via `RETURN ID(node) AS nodeId.
            
        edge_query: str. Cypher query to use for pulling down edge/relationship data.
            Should return the source node ID as "source" and the destination node ID
            as "destination".

        directed: bool. If False, please still provide a directed edge and node query,
            as the Dataset will automatically generate reverse edges on its own in a 
            sort order that accommodates DGL well.
            
        train_fraction: float in the range [0.0, 1.0]. Indicates the fraction of nodes to use
            for node classification task training.
            
        val_fraction: float in the range [0.0, 1.0]. Indicates the fraction of nodes to use
            for node classification task validation. Whatever number of nodes are left after
            training and validation are held out for testing.

        random_masks: bool. If True, train/val/test masks are generated by randomly
            selected node IDs from the full ID set. If False, masks are generated
            simply via consecutive index values (and thus the same masks will always
            be generated for the same dataset).
        '''
        self.neo4j_handler = connection_handler
        self.node_query = node_query
        self.edge_query = edge_query
        self.train_fraction = train_fraction
        self.val_fraction = val_fraction
        self.directed = directed
        self.random_masks = random_masks
        
        super().__init__(name='citations')

    def process(self):
        logger.debug("Pulling node data from Neo4j...")
        nodes_data = self.neo4j_handler.cypher_query_to_dataframe(self.node_query)
        logger.debug("Removing all nodes without a label of Train or Test...")
        nodes_data = nodes_data.explode('nodeTypes')
        nodes_data = nodes_data[nodes_data['nodeTypes'].isin(['Train', 'Test'])]
        self.nodes_data = nodes_data
        logger.debug("Node data pull complete")
        
        logger.debug("Pulling edge data from Neo4j...")
        edges_data = self.neo4j_handler.cypher_query_to_dataframe(self.edge_query)

        # Generate reversed edge list and append to end of original list
        if not self.directed:
            #TODO: consider removing this logic and adding dgl.add_reverse_edges(g) after graph creation instead
            edges_data_undirected = pd.DataFrame(
                np.concatenate(
                    (
                        edges_data['source'].values, 
                        edges_data['destination'].values
                    )
                ),
                columns = ['source']
            )

            edges_data_undirected['destination'] = np.concatenate(
                (
                    edges_data['destination'].values, 
                    edges_data['source'].values
                )
            )

            edges_data = edges_data_undirected

        # Make IDs for edges based on node position in nodes DataFrame
        edges_data = edges_data.merge(
            nodes_data.reset_index(drop=False)[['nodeId', 'index']], 
            how='inner', 
            left_on='source', 
            right_on='nodeId'
        ).rename(columns={'index': 'source_dgl'})

        edges_data = edges_data.merge(
            nodes_data.reset_index(drop=False)[['nodeId', 'index']], 
            how='inner', 
            left_on='destination', 
            right_on='nodeId'
        ).rename(columns={'index': 'destination_dgl'})
        self.edges_data = edges_data
        logger.debug("Edge data pull complete")
        
        #Process the data
        # Have to jump through some hoops to get lists into numpy arrays efficiently
        node_features = torch.from_numpy(np.array(nodes_data['features'].values.tolist()))
        node_labels = torch.from_numpy(np.array(nodes_data['labels'].values.tolist()))
        node_is_test = torch.from_numpy((nodes_data['nodeTypes'] == 'Test').values)
        #edge_features = torch.from_numpy(edges_data['Weight'].to_numpy())
        edges_src = torch.from_numpy(edges_data['source_dgl'].to_numpy())
        edges_dst = torch.from_numpy(edges_data['destination_dgl'].to_numpy())

        self.num_classes = node_labels.shape[1]
        logger.debug(f"CitationDataset has {self.num_classes} classes")

        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])
        self.graph.ndata['features'] = node_features
        self.graph.ndata['labels'] = node_labels
        self.graph.ndata['Test'] = node_is_test # Use to only get embeddings for Test nodes at inference time
        #self.graph.edata['weight'] = edge_features

        # If your dataset is a node classification dataset, you will need to assign
        # masks indicating whether a node belongs to training, validation, and test set.
        n_nodes = nodes_data.shape[0]

        if self.random_masks:
            node_ids = np.arange(n_nodes)

            train_nids, test_nids = train_test_split(
                node_ids, 
                train_size=self.train_fraction,
                test_size=1 - (self.train_fraction + self.val_fraction),
                shuffle=True, 
                random_state=None
            )

            # Leftover IDs are val_ids
            sorted_train_test_nids = np.sort(np.concatenate((train_nids, test_nids)))
            val_nids = node_ids[~np.isin(node_ids, sorted_train_test_nids)]

            train_mask = mask_from_ids(n_nodes, train_nids)
            val_mask = mask_from_ids(n_nodes, val_nids)
            test_mask = mask_from_ids(n_nodes, test_nids)

        else:
            n_train = int(n_nodes * self.train_fraction)
            n_val = int(n_nodes * self.val_fraction)
            
            train_mask = torch.zeros(n_nodes, dtype=torch.bool)
            val_mask = torch.zeros(n_nodes, dtype=torch.bool)
            test_mask = torch.zeros(n_nodes, dtype=torch.bool)
            
            train_mask[:n_train] = True
            val_mask[n_train:n_train + n_val] = True
            test_mask[n_train + n_val:] = True
        
        self.graph.ndata['train_mask'] = train_mask
        self.graph.ndata['val_mask'] = val_mask
        self.graph.ndata['test_mask'] = test_mask

        _ = split_edges(self.graph, store_in_graph=True)

    def __getitem__(self, i=None):
        '''
        Method for iterating across graphs in the Dataset.
        
        
        Parameters
        ----------
        i: int. Not used for single-graph Datasets, just here for API consistency.
        
        
        Returns
        -------
        The next DGL graph object.
        '''
        return self.graph

    def __len__(self):
        '''Number of graphs in the Dataset'''
        return 1

def load_reddit():
    from dgl.data import RedditDataset

    # load reddit data
    data = RedditDataset(self_loop=True)
    g = data[0]
    g.ndata['features'] = g.ndata['feat']
    g.ndata['labels'] = g.ndata['label']
    return g, data.num_classes

def load_ogb(name):
    from ogb.nodeproppred import DglNodePropPredDataset

    print('load', name)
    data = DglNodePropPredDataset(name=name)
    print('finish loading', name)
    splitted_idx = data.get_idx_split()
    graph, labels = data[0]
    labels = labels[:, 0]

    graph.ndata['features'] = graph.ndata['feat']
    graph.ndata['labels'] = labels
    in_feats = graph.ndata['features'].shape[1]
    num_labels = len(torch.unique(labels[torch.logical_not(torch.isnan(labels))]))

    # Find the node IDs in the training, validation, and test set.
    train_nid, val_nid, test_nid = splitted_idx['train'], splitted_idx['valid'], splitted_idx['test']
    train_mask = torch.zeros((graph.number_of_nodes(),), dtype=torch.bool)
    train_mask[train_nid] = True
    val_mask = torch.zeros((graph.number_of_nodes(),), dtype=torch.bool)
    val_mask[val_nid] = True
    test_mask = torch.zeros((graph.number_of_nodes(),), dtype=torch.bool)
    test_mask[test_nid] = True
    graph.ndata['train_mask'] = train_mask
    graph.ndata['val_mask'] = val_mask
    graph.ndata['test_mask'] = test_mask
    print('finish constructing', name)
    return graph, num_labels

def load_citations(db_ip, db_password, training_data=None, directed=True, features=['specterEmbeddingHugging']):
    '''
    Loads up Neo4j-based publication citation data for modeling.


    Parameters
    ----------
    training_data: bool. If True, limits nodes and edges only to those with the the 'Train'
        label. If False, limits to only nodes and edges with 'Test' label. If None, will
        not limit nodes and edges returned.

    directed: bool. Indicates if the graph to be built should have directed
        or undirected edges (True or False, resp.).

    features: list of str. Properties of Publication nodes that are of interest for 
        modeling.


    Returns
    -------
    2-tuple of the form (graph, num_node_classes).
    '''
    if training_data is None:
        node_label = ''    
    elif training_data:
        node_label = ':Train'
    else:
        node_label = ':Test'
    
    # Concatenate feature vectors
    feature_list = ['p.' + f for f in features]
    features_string = ' + '.join(feature_list)

    node_query = f"""
    MATCH (p:Publication{node_label})-[:CITED_BY]->(:Publication)
    RETURN DISTINCT ID(p) AS nodeId, labels(p) AS nodeTypes, {features_string} AS features, p.label_vector AS labels
    """

    edge_query = f"""
    MATCH (p:Publication{node_label})-[rel:CITED_BY]->(p2:Publication{node_label})
    RETURN ID(p) AS source, ID(p2) AS destination
    """

    dataset = CitationDataset(
        connection_handler=Neo4jConnectionHandler(
            db_ip=db_ip,
            db_password=db_password
        ), 
        node_query=node_query, 
        edge_query=edge_query,
        directed=directed,
        random_masks=True
    )
    graph = dataset[0]

    
    return graph, dataset.num_classes

def inductive_split(g):
    """
    Split the graph into training graph, validation graph, and test graph by 
    using node masks.  Suitable for inductive models.
    """
    train_g = g.subgraph(g.ndata['train_mask'])
    #val_g = g.subgraph(g.ndata['train_mask'] | g.ndata['val_mask']) # Why does this seem to include both val and train sets? Because it's unsupervised?
    #test_g = g # Entire graph as test? Interesting. Must be referring not to hold out case but final model training? Yikes.

    val_g = g.subgraph(g.ndata['val_mask'])
    test_g = g.subgraph(g.ndata['test_mask'])
    
    return train_g, val_g, test_g

def split_edges(g, triplet_type='full', store_in_graph=False):
    '''
    Given a DGL graph with train, val, and test masks defined, return the edge IDs
    associated with each mask. 

    Note that ``triplet_type=='full'`` will ignore edges between nodes of different
    masks (e.g. (train)--(test)), but the other two types should capture all edges.
    
    
    Parameters
    ----------
    g: DGL graph that must contain node properties 'train_mask', 'val_mask', 
        and 'test_mask'. Each of these properties is assumed to be a 
        1D Pytorch Tensor.
    
    triplet_type: str. Must be one of ['full', 'src', 'dest']:
        'full': assumes an edge of a particular mask (e.g. training) 
                is only counted if both the source and destination 
                nodes are of the same mask (e.g. (train)->(train))

        'src': assumes only the source node of any given edge must belong
                to the mask in question to count the edge as also belonging
                to it.

        'dest': same as 'src' except the destination node is the deciding 
                criterion.

    store_in_graph: bool. If True, write the edge masks to the ``g`` directly
        as an edge property (e.g. accessible via g.edata['train_mask']).


    Returns
    -------
    3-tuple of edge ID tensors for the three masks, of the form 
    (train_edge_ids, val_edge_ids, test_edge_ids)
    '''
    for mask in ['train_mask', 'val_mask', 'test_mask']:
        if mask not in g.ndata: 
            raise ValueError(f"Graph nodes are missing '{mask}' property")

    train_nids = ids_from_masks(g, 'train_mask', 'nodes').numpy()
    val_nids = ids_from_masks(g, 'val_mask', 'nodes').numpy()
    test_nids = ids_from_masks(g, 'test_mask', 'nodes').numpy()

    # Get edges in form (src_nodes_tensor, dest_nodes_tensor, eids_tensor)
    # With ordering of everything dictated by source node ID then dest node ID
    edges = torch.stack(g.edges(form='all'))

    if triplet_type == 'full':
        train_mask_edges_src = np.isin(edges[0].numpy(), train_nids).astype(int)
        val_mask_edges_src = np.isin(edges[0].numpy(), val_nids).astype(int)
        test_mask_edges_src = np.isin(edges[0].numpy(), test_nids).astype(int)
        
        train_mask_edges_dest = np.isin(edges[1].numpy(), train_nids).astype(int)
        val_mask_edges_dest = np.isin(edges[1].numpy(), val_nids).astype(int)
        test_mask_edges_dest = np.isin(edges[1].numpy(), test_nids).astype(int)

        # Add the 0/1 values together and look for anything that's == 2 
        # (both src and dest nodes are training nodes)
        train_mask_edges = (train_mask_edges_src + train_mask_edges_dest) == 2
        val_mask_edges = (val_mask_edges_src + val_mask_edges_dest) == 2
        test_mask_edges = (test_mask_edges_src + test_mask_edges_dest) == 2

    elif triplet_type == 'src':
        train_mask_edges = np.isin(edges[0].numpy(), train_nids)
        val_mask_edges = np.isin(edges[0].numpy(), val_nids)
        test_mask_edges = np.isin(edges[0].numpy(), test_nids)

    elif triplet_type == 'dest':
        train_mask_edges = np.isin(edges[1].numpy(), train_nids)
        val_mask_edges = np.isin(edges[1].numpy(), val_nids)
        test_mask_edges = np.isin(edges[1].numpy(), test_nids)

    else:
        raise ValueError(f"`triplet_type` must be one of ['full', 'src', 'dest'], "
        f"but '{triplet_type}' was passed")

    output_masks = tuple(torch.Tensor(e).bool() for e in [train_mask_edges, val_mask_edges, test_mask_edges])

    if store_in_graph:
        for i, label in enumerate(['train_mask', 'val_mask', 'test_mask']):
            g.edata[label] = output_masks[i]

    # Use the masks to pull out edge IDs
    return tuple(edges[2][e] for e in output_masks)

class SAGE(nn.Module):
    def __init__(self, in_feats, n_hidden, n_classes, n_layers, activation, dropout, agg_type='mean'):
        super().__init__()
        self.init(in_feats, n_hidden, n_classes, n_layers, activation, dropout, agg_type)

    def init(self, in_feats, n_hidden, n_classes, n_layers, activation, dropout, agg_type):
        self.n_layers = n_layers
        self.n_hidden = n_hidden
        self.n_classes = n_classes
        self.layers = nn.ModuleList()
        
        if n_layers > 1:
            self.layers.append(dglnn.SAGEConv(in_feats, n_hidden, agg_type))
            for i in range(1, n_layers - 1):
                self.layers.append(dglnn.SAGEConv(n_hidden, n_hidden, agg_type))
            #self.layers.append(dglnn.SAGEConv(n_hidden, n_classes, agg_type))
            self.layers.append(dglnn.SAGEConv(n_hidden, n_hidden, agg_type))
        else:
            #self.layers.append(dglnn.SAGEConv(in_feats, n_classes, agg_type))
            self.layers.append(dglnn.SAGEConv(in_feats, n_hidden, agg_type))
        self.dropout = nn.Dropout(dropout)
        self.activation = activation

    def forward(self, blocks, x):
        h = x.float()
        for l, (layer, block) in enumerate(zip(self.layers, blocks)):
            h = layer(block, h)
            if l != len(self.layers) - 1: # Run hidden state through activation and then Dropout layers IF not the final SAGE layer
                h = self.activation(h)
                h = self.dropout(h) 
        return h

class NegativeSampler(object):
    def __init__(self, g, k, neg_share=False):
        '''
        Samples non-existent edges from connected source nodes
        to generate new negative edges for link prediction/unsupervised
        learning.


        Parameters
        ----------
        g: DGL graph.

        k: int. Also called `num_negs` elsewhere in the code.
            Dictates the number of negative examples per edge.
            Effectively will duplicate the negative source nodes
            but not necessarily duplicate negative edges (but may).

        neg_share: bool. If True, and the number of nodes in ``g`` is
            evenly divisble by ``k``, will effectively use the same 
            destination nodes ``k`` times for negative edge examples,
            increasing their importance with regards to training the model.
        '''
        # Creates node sampling weights according to 
        # a power-law distribution of (in_degrees ^ 0.75)
        self.weights = g.in_degrees().float() ** 0.75
        self.k = k
        self.neg_share = neg_share

    def __call__(self, g, eids):
        # Get source node IDs for the edges of interest
        src, _ = g.find_edges(eids)
        n = len(src)

        # If neg_share is True AND n is a multiple of k...
        if self.neg_share and n % self.k == 0:
            # Make a tensor with `n` node IDs sampled from the
            # multinomial probability distribution
            # This effectively means that only nodes with 1+ edges
            # will be sampled and that those with higher in_degrees
            # (which marks them as a destination node) will be more
            # likely
            dst = self.weights.multinomial(n, replacement=True)

            # Effectively creates a view of the destination nodes that
            # is n*k in length (instead of just n), copying values as
            # needed to make that work
            dst = dst.view(-1, 1, self.k).expand(-1, self.k, -1).flatten()

        else:
            if self.neg_share:
                logger.debug(f"neg_share set to True, but overriding "
                f"as number of nodes in batch ({n}) is not evenly "
                f"divisible by num_negs AKA `k` ({self.k}). As such, "
                "there is no guarantee that negative source nodes will be "
                "oversampled.")
            dst = self.weights.multinomial(n*self.k, replacement=True)

        # Repeats node IDs `k` times
        src = src.repeat_interleave(self.k)
        return src, dst

class CrossEntropyLoss(nn.Module):
    #TODO: do we want to use cross entropy loss though? Not sure it's good for links that *should* exist but simply don't
    def forward(self, block_outputs, pos_graph, neg_graph):
        with pos_graph.local_scope():
            pos_graph.ndata['h'] = block_outputs
            pos_graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))
            pos_score = pos_graph.edata['score']
        with neg_graph.local_scope():
            neg_graph.ndata['h'] = block_outputs
            neg_graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))
            neg_score = neg_graph.edata['score']

        # Make the scores 1D
        score = torch.cat([pos_score, neg_score])

        # Make all positive scores have label of 1, all negative ones 0
        label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)]).long()
        loss = F.binary_cross_entropy_with_logits(score, label.float())
        return loss

class SAGELightning(LightningModule):
    def __init__(self,
                 in_feats,
                 n_hidden,
                 n_classes,
                 n_layers,
                 activation,
                 dropout,
                 lr,
                agg_type):
        super().__init__()
        self.module = SAGE(in_feats, n_hidden, n_classes, n_layers, activation, dropout, agg_type)
        self.lr = lr
        self.loss_fcn = CrossEntropyLoss()
        #self.device = device

        self.save_hyperparameters()

    def training_step(self, batch, batch_idx):
        input_nodes, pos_graph, neg_graph, mfgs = batch
        mfgs = [mfg.int().to(self.device) for mfg in mfgs]
        pos_graph = pos_graph.to(self.device)
        neg_graph = neg_graph.to(self.device)
        batch_inputs = mfgs[0].srcdata['features']
        batch_labels = mfgs[-1].dstdata['labels']
        batch_pred = self.module(mfgs, batch_inputs)
        loss = self.loss_fcn(batch_pred, pos_graph, neg_graph)
        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)
        return loss

    def validation_step(self, batch, batch_idx):
        '''
        #TODO: figure out how to make this track proper loss values in addition to F1 scores
            Probably need val_dataloader to spit out a EdgeDataLoader like train_dataloader does
            AND a NodeDataLoader as val_dataloader does currently. That way we can use the exact some
            loss function we used in training too.

            Problem is, the validation_step has issues when I use the NodeDataLoader
            to generate predictions for at-epoch-end F1 scoring without saving something
            to the logger and UnsupervisedClassification has issues when I return nothing
            for the validation data after using edge values for loss. This would be MUCH
            easier if validation dataloaders could be referenced by key instead of having
            to pass a single one per validation_step() call...


        Parameters
        ----------
        batch: EdgeDataLoader object.

        batch_idx: int. Index of the batch relative to original
            creation position.


        Returns
        -------
        torch.Tensor of batch predictions when using the NodeDataLoader, otherwise
        return nothing.
        '''         

        input_nodes, pos_graph, neg_graph, mfgs = batch
        mfgs = [mfg.int().to(self.device) for mfg in mfgs]
        pos_graph = pos_graph.to(self.device)
        neg_graph = neg_graph.to(self.device)
        batch_inputs = mfgs[0].srcdata['features']
        batch_labels = mfgs[-1].dstdata['labels']
        batch_pred = self.module(mfgs, batch_inputs)
        loss = self.loss_fcn(batch_pred, pos_graph, neg_graph)
        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optimizer

    # Save time and memory since this is pure inference
    @torch.no_grad()
    def predict(self, g, x, batch_size, num_workers, output_nids=None):
    #def predict_step(self, batch, batch_idx):
        """
        Inference with the GraphSAGE model using all 1-hop neighbors 
        (i.e. without neighbor sampling). By default trainer.predict() will use
        Train nodes as the input data if no DataLoader or DataModule is provided.

        Note: this method is written such that it can handle a different number of nodes
        than what was used for model training (since graphSAGE is inductive, after all)
        and be used on an arbitrarily large graph for offline inference. BUT note that
        it will likely be slow on very large graphs, since 1-hop neighbors aren't being 
        sampled (which is what we do in training) but rather fully utilized.

        Also note: during inference with sampling, multi-layer blocks are very 
        inefficient because lots of computations in the first few layers are 
        repeated. Therefore, we compute the representation of all nodes layer by 
        layer.  The nodes on each layer are of course splitted in batches. 
        Unfortunately this means that we can't use pytorch-lightning's built in 
        prediction methods, because they assume you'll pass one batch at time
        the prediction step, instead of needing to parse all batches at once per
        layer.


        Parameters
        ----------
        g: DGL graph object. The entire graph to be used in inference. Can often be pulled
            (at least for training nodes) from ``datamodule.g``.

        x: PyTorch Tensor object. The input of entire node set. Should be equivalent feature set
            as whatever was used for input when training the model. Should be of the shape
            (num_nodes_in_g, features_shape).
        
        batch_size: int. Number of nodes to run inference on together.
        
        num_workers: int. Number of threads to spin up to build out the 
            NodeDataLoader for inference.
        
        output_nids: PyTorch Tensor. Provides the node IDs for the nodes you want output from.
            `torch.nonzero(g.ndata['Test'], as_tuple=True)[0]` is commonly used. If None,
            all nodes in ``g`` will be assumed.


        Returns
        -------
        PyTorch Tensor of the shape (num_nodes, embedding_shape).
        """
        # Note that "neighbors" in DGL terminology seems to be single-hop only!

        if self.training:
            logger.error("Model was not set to eval mode! Setting now...")
            self.eval()

        for l, layer in enumerate(self.module.layers):
            #y = torch.zeros(g.num_nodes(), self.n_hidden if l != len(self.layers) - 1 else self.n_classes)
            y = torch.zeros(g.num_nodes(), self.module.n_hidden)

            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)
            dataloader = dgl.dataloading.NodeDataLoader(
                g,
                torch.arange(g.num_nodes()).to(g.device) if output_nids is None else output_nids.to(g.device),
                sampler,
                batch_size=batch_size,
                shuffle=True, #TODO: allow this or not due to temporal nature?
                drop_last=False,
                num_workers=num_workers)

            for input_nodes, output_nodes, blocks in tqdm.tqdm(dataloader, 
            desc=f'Going through batches on layer {l}'):
                block = blocks[0]

                block = block.int().to(self.device)
                h = x[input_nodes].to(self.device)
                h = layer(block, h)
                if l != len(self.module.layers) - 1:
                    h = self.module.activation(h)
                    h = self.module.dropout(h)

                y[output_nodes] = h.cpu()

            x = y
        return y

    def on_train_end(self):
        '''
        Called at the end of Trainer.fit(), the last thing done before experiment
        logging is closed down.


        Parameters
        ----------
        None.


        Returns
        -------
        Nothing. 
        '''
        logger.info("Running testbed classification...")
        batch_size = 512

        # Pulling down only Train nodes for Train node embedding inference...
        # The Train nodes should only know about Train-Train edges
        g, _ = load_citations(
            training_data=True, 
            directed=DIRECTED, 
            features=['specterEmbeddingHugging', 'feature_vector']
        )

        # Making graphSAGE embeddings for Train nodes
        sage_embeddings_train = self.predict(g, g.ndata['features'].float(), batch_size, num_workers=10)
        labels_train = g.ndata['labels']

        # Pulling down full citation graph for Test node embedding inference...
        # The Test nodes should know about Train-Test as well as Test-Test edges
        g, _ = load_citations(
            training_data=None, 
            directed=DIRECTED, 
            features=['specterEmbeddingHugging', 'feature_vector']
        )

        # Building graphSAGE embeddings for Test nodes using full graph (Train + Test)...
        sage_embeddings_test = self.predict(
            g, 
            g.ndata['features'].float(), 
            batch_size, 
            num_workers=10
        )[g.ndata['Test']] # Filter out only the results from Test nodes

        test_nids = torch.nonzero(g.ndata['Test'], as_tuple=True)[0]
        labels_test = g.nodes[test_nids].data['labels']

        # Standardize the embeddings like is done in the validation step of training
        scaler = StandardScaler()
        sage_embeddings_train_scaled = scaler.fit_transform(sage_embeddings_train.numpy())
        sage_embeddings_test_scaled = scaler.transform(sage_embeddings_test.numpy())

        classifier = MultiOutputClassifier(
            lm.SGDClassifier(
                loss="log", 
                random_state=42, 
                shuffle=True
            ), 
            n_jobs=10
        ) 
        classifier.fit(sage_embeddings_train_scaled, labels_train.numpy())

        # Calculate the f1 score on test data
        f1 = skm.f1_score(labels_test.numpy(), 
                    classifier.predict(sage_embeddings_test_scaled), average="micro")
        logger.info(f"f1 score on classification testbed is {f1}")

        # Log the results to W&B
        #self.log("f1_micro_Test", f1) # this doesn't work yet, maybe in v1.4?
        self.logger.experiment.log({"f1_micro_Test": f1})


class DataModule(LightningDataModule):
    def __init__(self, dataset_name, features=None, data_cpu=False, fan_out=[10, 25],
                 device=torch.device('cpu'), batch_size=1000, num_workers=4,
                 num_negs=1, neg_share=False):
        
        '''
        Loads up our dataset and defines the training and validation subsets
        for PyTorch Lightning training.


        Parameters
        ----------
        dataset_name: str. Just a label to indicate what the dataset is and
            determine which data ingest algorithm to use. Can be one of 
            ['reddit', 'ogbn-products', 'citations'].

        features: list of str indicating node attributes to use as
            model features. Currently only used when dataset_name='citations'.
            For Neo4j data loads (e.g. 'citations' dataset), just provide the node
            property name (e.g. 'feature_vector' not 'p.feature_vector').

            At least one feature provided via this argument should be a list/array 
            unto itself, as all features are concatenated when pulled and Neo4j
            doesn't concatenate scalars/strings.

        data_cpu: bool. If False, pushes the data into the GPU for training and inference.

        fan_out: list of int. The size of the list should match the number of model layers
            The values determine how many neighbors will be sampled in each layer.

        device: torch.device() object. Indicates if GPU or CPU should be used for model
            training.

        batch_size: int. Number of nodes per training batch before weights
            are updated via backprop.

        num_workers: Number of processes to use for loading up data.

        num_negs: int. Also called `num_negs` elsewhere in the code.
            Dictates the number of negative examples per edge.
            Effectively will duplicate the negative source nodes
            but not necessarily duplicate negative edges (but may).

        neg_share: bool. If True, and the number of nodes in ``g`` is
            evenly divisble by ``k``, will effectively use the same 
            destination nodes ``k`` times for negative edge examples,
            increasing their importance with regards to training the model.
        '''
        super().__init__()
        self.num_negs = num_negs
        self.neg_share = neg_share
        self.batch_size = batch_size
        self.feature_list = features

        if dataset_name == 'reddit':
            g, n_classes = load_reddit()
            n_edges = g.num_edges()
            reverse_eids = torch.cat([
                torch.arange(n_edges // 2, n_edges),
                torch.arange(0, n_edges // 2)])
        elif dataset_name == 'ogbn-products':
            g, n_classes = load_ogb('ogbn-products')
            n_edges = g.num_edges()
            # The reverse edge of edge 0 in OGB products dataset is 1.
            # The reverse edge of edge 2 is 3.  So on so fortorch.
            reverse_eids = torch.arange(n_edges) ^ 1
        elif dataset_name == 'citations':
            directed = True #TODO: find a good way to pass this
            g, n_classes = load_citations(
                training_data=True, #TODO: is there a better way to do this?
                directed=directed,
                features=features
            )
            n_edges = g.num_edges()
            
            if directed:
                reverse_eids = None
            else:
                reverse_eids = torch.cat([
                    torch.arange(n_edges // 2, n_edges),
                    torch.arange(0, n_edges // 2)
                ])
        else:
            raise ValueError('unknown dataset')

        # Extract node IDs for each of the dataset split groups
        train_nid = torch.nonzero(g.ndata['train_mask'], as_tuple=True)[0]
        val_nid = torch.nonzero(g.ndata['val_mask'], as_tuple=True)[0]
        test_nid = torch.nonzero(~(g.ndata['train_mask'] | g.ndata['val_mask']), as_tuple=True)[0]

        sampler = dgl.dataloading.MultiLayerNeighborSampler([int(_) for _ in fan_out])

        dataloader_device = torch.device('cpu')
        if not data_cpu:
            train_nid = train_nid.to(device)
            val_nid = val_nid.to(device)
            test_nid = test_nid.to(device)
            g = g.formats(['csc'])
            g = g.to(device)
            dataloader_device = device

        self.g = g
        self.train_nid, self.val_nid, self.test_nid = train_nid, val_nid, test_nid
        self.sampler = sampler
        self.device = dataloader_device
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.in_feats = g.ndata['features'].shape[1]
        self.n_classes = n_classes
        self.reverse_eids = reverse_eids

    def train_dataloader(self):
        train_eids = torch.nonzero(self.g.edata['train_mask'], as_tuple=True)[0]

        return dgl.dataloading.EdgeDataLoader(
            self.g,
            #np.arange(self.g.num_edges()), # I think this is a mistake for edge IDs...it gets all train, val, and test nodes as a result!
            train_eids,
            self.sampler,

            # If exclude='reverse_id', doesn't sample an edge if it is
            # the reversed version of an already-sampled edge
            # This appears to effectively force sampling to treat graph as directed...
            exclude='reverse_id' if self.reverse_eids is not None else None,
            reverse_eids=self.reverse_eids, # ignored if ``exclude`` is None
            negative_sampler=NegativeSampler(self.g, self.num_negs, self.neg_share),
            device=self.device,
            batch_size=self.batch_size,
            shuffle=True,
            drop_last=False,
            num_workers=self.num_workers)

    def val_dataloader(self):
        '''
        Loads up data to be used for inference in the validation steps.


        Parameters
        ----------
        None.


        Returns
        -------
        Iterable of batches of data, wherein each batch is a 
        list of batches of the form [node_loader, edge_loader].

        Node loader is used for validating via node classification, 
        edge loader is used for validating via loss function (just like
        how it's done in the training step).
        '''
        val_eids = ids_from_masks(self.g, 'val_mask', data_type='edges')
        # Add test edges too, since we aren't using them as a test set elsewhere
        test_eids = ids_from_masks(self.g, 'test_mask', data_type='edges')
        val_eids = torch.cat((val_eids, test_eids))

        loader = dgl.dataloading.EdgeDataLoader(
            self.g,
            #np.arange(self.g.num_edges()),
            val_eids,
            self.sampler,
            exclude='reverse_id' if self.reverse_eids is not None else None,
            reverse_eids=self.reverse_eids, # ignored if ``exclude`` is None
            negative_sampler=NegativeSampler(self.g, self.num_negs, self.neg_share),
            device=self.device,
            batch_size=self.batch_size,
            shuffle=True,
            drop_last=False,
            num_workers=self.num_workers)

        return loader

#def compute_acc_unsupervised(datamodule, emb, labels, train_nids, val_nids, test_nids):
    """
    Compute the accuracy of prediction given the labels.
    """
    # argmax un-dummifies labels to make 1D target vector
    # So missing examples with a certain class doesn't cause errors

    """ emb = emb.cpu().numpy()
    labels = labels.cpu().numpy()
    train_nids = train_nids.cpu().numpy()
    train_labels = labels[train_nids].argmax(axis=1)
    datamodule.train_labels = train_labels#.argmax(axis=1)
    datamodule.embedding = emb[train_nids]

    val_nids = val_nids.cpu().numpy()
    val_labels = labels[val_nids].argmax(axis=1)
    test_nids = test_nids.cpu().numpy()
    test_labels = labels[test_nids].argmax(axis=1)

    # Standardize the embedding...because it isn't already I guess?
    emb = (emb - emb.mean(0, keepdims=True)) / emb.std(0, keepdims=True)

    lr = lm.SGDClassifier(loss="log", random_state=42, shuffle=False)
    lr.fit(emb[train_nids], train_labels)

    pred = lr.predict(emb)
    f1_micro_eval = skm.f1_score(val_labels, pred[val_nids], average='micro')
    f1_micro_test = skm.f1_score(test_labels, pred[test_nids], average='micro')
    return f1_micro_eval, f1_micro_test """

class UnsupervisedClassification(Callback):
    def on_validation_epoch_start(self, trainer, pl_module):
        self.val_outputs = []

    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):
        self.val_outputs.append(outputs)

    def on_validation_epoch_end(self, trainer, pl_module):
        node_emb = torch.cat(self.val_outputs, 0)
        g = trainer.datamodule.g
        labels = g.ndata['labels']
        f1_micro, f1_macro = compute_acc_unsupervised(
            trainer.datamodule,
            node_emb, labels, trainer.datamodule.train_nid,
            trainer.datamodule.val_nid, trainer.datamodule.test_nid)
        pl_module.log('val_f1_micro', f1_micro)

